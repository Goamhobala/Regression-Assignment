---
# The two fields that are not in the elsevier format are:
title: STA2005S - Regression Assignment
date: "`r Sys.Date()`"

author:
  - name: Jing Yeh
    email: yhxjin001@myuct.ac.za
  - name: Saurav Sathnarayan
    email: sthsau001@myuct.ac.za
nocite: '@*'

abstract: In this report, we explored the efficiency of 6 programming languages through the approximation of $\pi$. We found that efficiency of various programming languages can vary widely, with C and C++ being the most efficient programming languages. We also presented evidence for compiled languages having better performance than interpreted languages. Our results suggest that programmers can benefit from taking the efficiency of various programming languages into account, rather than simply opting for simplicity in the syntax of these languages .
  
keywords: Programming Languages, Efficieny, Large-Scaled Iterative Compuations 
  
#bibliography: mybibfile.bib
#nocite: '@*'
  
#csl: https://www.zotero.org/styles/oxford-university-press-note
#fontsize: 12pt
#spacing: halfline # could also be oneline
#classoptions:
#link-citations: yes
#urlcolor: orange
#linkcolor: green
#citecolor: red
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
  \usepackage{caption}
  \captionsetup[figure]{font=scriptsize}
output:
  pdf_document:
    
    fig_caption: true
    number_sections: true
  oup_version: 0 # 1 = 2020 CTAN OUP CLS package; 0 = 2009 OUP CLS package
  extra_dependencies: booktabs # for kable example
  rticles::oup_article:
editor_options: 
  markdown: 
    wrap: 72
---
\newpage
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#| results: hide
#| warning: false
#| message: false
#| error: false
if (!requireNamespace("remotes", quietly = TRUE)) {
install.packages("remotes")
}
remotes::install_github("MiguelRodo/DataTidyRodoSTA2005S")
data("data_tidy_air_quality", package = "DataTidyRodoSTA2005S")

library(ggplot2)
library(tidyr)
library(kableExtra)
```

# Part One : Analysis

## Section 1: Introduction

Air pollution, particularly high levels of particulate matter (PM), is a major environmental and public health issue in South Africaâ€™s urban centers. Exposure to elevated PM levels is linked to respiratory diseases and other serious health conditions. Understanding the factors influencing PM concentrations is crucial for developing policies that improve air quality and protect public health. This analysis seeks to identify the key drivers of air pollution in South Africa's cities, focusing on how various urban, environmental, and socioeconomic factors affect particulate matter levels.

Unknown Factors to Investigate:

Traffic Density: How do varying levels of vehicle traffic contribute to PM levels in different areas?

Industrial Activity: What is the impact of industrial activity near monitoring stations on air quality?

Temperature & Humidity: How do changes in weather conditions, like temperature and humidity, influence PM concentrations?

Wind Speed: How does wind speed affect the dispersion or accumulation of particulate matter in urban areas?

Day of the Week & Public Holidays: Do patterns of human activity on weekdays, weekends, and holidays significantly influence pollution levels?

Urban Greenery: How effective are green spaces in reducing air pollution in densely populated areas?

# Objective

The goal of this analysis is to explore the relationships between PM levels and these explanatory variables. By identifying the most influential factors, we aim to inform urban planning and public health strategies that address air pollution and improve the quality of life in South African cities.


## Section 2 : Data Exploration

### Density plot

```{r pressure, echo=FALSE, warning=FALSE}
mean_particle <- mean(data_tidy_air_quality$particulate_matter)
sd_particle <- sd(data_tidy_air_quality$particulate_matter)

ggplot(data_tidy_air_quality, aes(x=particulate_matter))+
  geom_histogram(fill="deepskyblue3", color="black", binwidth = 3, aes(y=..density..))+
  stat_function(fun=dnorm, args=list(mean=mean_particle, sd=sd_particle), color="firebrick4", size=1.2)+
  labs(title="Density Plot of Particulate Matter", y="Density", x="Particulate Matter")
```

### Pairwsie Plots

```{r echo=FALSE, warning=FALSE}
continuous_vars <- data_tidy_air_quality[, sapply(data_tidy_air_quality, is.numeric)]
pairs(continuous_vars, main = "Pairwise Scatterplots of Continuous Variables", col="deepskyblue3")
```

### Categorial Variable Plots

```{r echo=FALSE, warning=FALSE}
data_tidy_air_quality$industrial_activity <- factor(data_tidy_air_quality$industrial_activity, 
                                   levels = c("None","Low", "Moderate", "High"))  # Adjust the levels according to your data

data_tidy_air_quality$day_of_week <- factor(data_tidy_air_quality$day_of_week, 
                           levels = c("Monday", "Tuesday", "Wednesday", 
                                      "Thursday", "Friday", "Saturday", "Sunday"))

data_tidy_air_quality$holiday <- factor(data_tidy_air_quality$holiday, 
                           levels = c("Yes", "No"))

categorical_vars <- names(data_tidy_air_quality)[sapply(data_tidy_air_quality, is.factor)]
colours_vector <- c("industrial_activity", "day_of_week", "holiday")

for (var in categorical_vars) {
  plt<- ggplot(data_tidy_air_quality, aes_string(x = var, y = "particulate_matter")) +
    geom_boxplot(fill="deepskyblue3", color="firebrick4", size=1) +
    labs(title = paste("Particulate Matter vs", var),
         x = var,
         y = "Particulate Matter") +
    theme_minimal() 
    
  
  print(plt)  # Print the plot
}
```

### Visual Representation of Relationship between Categorial Variables
```{r echo=FALSE, message=FALSE, warning=FALSE}
for (i in 1:(length(categorical_vars) - 1)) {
  for (j in (i + 1):length(categorical_vars)) {
    # Create the plot
    p <- ggplot(data_tidy_air_quality, aes_string(x = categorical_vars[i], fill = categorical_vars[j])) +
      geom_bar(position = "fill") +  # Use "fill" to make it a stacked bar chart (proportions)
      labs(title = paste("Stacked Bar Chart of", categorical_vars[i], "and", categorical_vars[j]),
           x = categorical_vars[i],
           y = "Proportion") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
    
    # Print the plot
    print(p)
  }
}
```

### Comments

Distribution characterisitcs:

The distribution of particulate matter levels is generally right-skewed, indicating that a small number of observations have significantly high levels of particulate matter while most observations are clustered at lower levels. The presence of outliers suggests variations in local conditions affecting air quality.

Observed Relationships

1. Traffic Density: A positive correlation exists between particulate matter levels and traffic density, suggesting that areas with higher vehicle traffic tend to experience elevated levels of particulate matter.

2. Urban Greenery: A negative trend is observed, where higher urban greenery correlates with lower particulate matter, indicating that vegetation may help mitigate air pollution.

3. Temperature and Wind Speed: No strong relationship was identified between particulate matter and temperature. However, there is a slight negative correlation with wind speed, indicating that higher wind speeds may help disperse particulate matter.

Potential Collinearity

Some potential collinearity is observed among the explanatory variables, particularly between traffic density and urban greenery. High traffic areas often have less vegetation, leading to a relationship that may confound the analysis. Additionally, temperature and wind speed may also exhibit collinearity, as changes in one could affect the other.

# Section 3
## Simple linear regression
```{r echo=FALSE, message=FALSE, warning=FALSE}

n <- length(data_tidy_air_quality$traffic_density)
X_bar <- mean(data_tidy_air_quality$traffic_density)
Y_bar <- mean(data_tidy_air_quality$particulate_matter)

X <- cbind(1,data_tidy_air_quality$traffic_density)
Y <-data_tidy_air_quality$particulate_matter

bhat <- solve(t(X) %*% X) %*% t(X) %*% Y
Cmat <- solve(t(X) %*% X)

k <- ncol(X)
rss <- t(Y - X %*% bhat) %*% (Y - X %*% bhat)

s2 <- as.numeric((rss)/n-k)


c_ii <- diag(Cmat)

std.error <- sqrt(s2 * c_ii)


t_beta_0<- bhat[1]/std.error[1]
t_beta_1<- bhat[2]/std.error[2]



p_beta_1 <-2* pt(t_beta_0, df = n-k,lower.tail=FALSE)
p_beta_0 <-2* pt(t_beta_0, df = n-k,lower.tail=FALSE)

Y_hat <- bhat[1] + bhat[2]*data_tidy_air_quality$traffic_density
residuals <- data_tidy_air_quality$particulate_matter - Y_hat

SSE <- sum(residuals^2)
SST <- sum((data_tidy_air_quality$particulate_matter - Y_bar)^2)


R_squared <- (1 - (SSE / SST)) 

Adjusted_R_squared <- 1 - (1 - R_squared) * ((n - 1) / (n - k))

F_statistic <- (SST - SSE) / (SSE / (n-2))


coefficients <- data.frame(
  Estimate = c(bhat[1], bhat[2]),
  `Std. Error` = c(std.error[1], std.error[2]),
  `t value` = c(t_beta_0, t_beta_1),
  `Pr(>|t|)` = c(p_beta_0, p_beta_1)
)
rownames(coefficients) <- c("(Intercept)", "traffic_density")

cat("Coefficients:\n")
print.data.frame(coefficients)

cat("\nResidual standard error:",sqrt(s2),"on 1 and", n-2, "DF" )
cat("\nMultiple R-squared:",R_squared, "Adjusted R-Squared: ",Adjusted_R_squared)
cat("\nF-statistic:",F_statistic, "on 1 and", n-2, "DF")

#differences in values and lm function values are due to the rounding.
```

## Hypothesis Test

```{r echo=TRUE}
# Calculate F-statistic and p-value manually
group_means <- tapply(data_tidy_air_quality$particulate_matter,
                      data_tidy_air_quality$industrial_activity, mean)
overall_mean <- mean(data_tidy_air_quality$particulate_matter)

# Calculate SST
SST <- sum((data_tidy_air_quality$particulate_matter - overall_mean)^2)

# Calculate SStreatment
n <- table(data_tidy_air_quality$industrial_activity)
SStreatment <- sum(n * (group_means - overall_mean)^2)

# Calculate SSerror
group_means_vector <- unlist(tapply(data_tidy_air_quality$particulate_matter, data_tidy_air_quality$industrial_activity, mean)
[data_tidy_air_quality$industrial_activity])
SSerror <- sum((data_tidy_air_quality$particulate_matter - group_means_vector)^2)

# Calculate degrees of freedom
k <- length(unique(data_tidy_air_quality$industrial_activity))
N <- nrow(data)
DFtreatment <- k - 1
DFerror <- 150 - k

# Calculate Mean Squares
MStreatment <- SStreatment / DFtreatment
MSerror <- SSerror / DFerror


# Calculate F-statistic
F_statistic <- MStreatment/MSerror
F_statistic

# Calculate p-value
p_value <- pf(F_statistic, DFtreatment, DFerror, lower.tail = FALSE)
p_value
```

\newpage

# Question 4
```{r, echo=FALSE}
# Question4
data_tidy_air_quality$industrial_activity <- relevel(factor(data_tidy_air_quality$industrial_activity), ref="None")
multi_model <- lm(particulate_matter ~ . + temperature:humidity, data=data_tidy_air_quality)
estimates <- as.data.frame(summary(multi_model)$coefficients)

confint_df <- as.data.frame(confint(multi_model))
confint_df$Estimate <- as.numeric(estimates$Estimate)
confint_rows <-row.names(confint_df)
row_orders = c(confint_rows[1:8], "temperature:humidity", confint_rows[10:length(confint_rows) - 1])
confint_df_reordered <- confint_df[row_orders,c("2.5 %", "Estimate", "97.5 %")]

confint_table <- kable(confint_df_reordered, digits = 4, align="c", caption="Confidence Interval for each Coefficient") |>
  kable_styling(font_size = 12) |>
  pack_rows(index= c("Intercept"=1, "Traffic Density"=1, "Industrial Activity"=3, "Natural Factors" = 4, "Day of Week"=6, "Holiday"=1, "Urban Greenery"=1))
#summary_table
confint_table




estimates <- estimates[-c(1),]
colnames(estimates)[4] <- "P-value"

estimates.rows <- row.names(estimates)
row_orders = c(estimates.rows[1:7], "temperature:humidity", estimates.rows[9:15])

estimates_df_reordered <- estimates[row_orders,]
summary_table <- kable(estimates_df_reordered, digits = 4, align="c", caption="Summary of the Model") |>
  kable_styling(font_size = 12)
summary_table

```



## Hypothesis Testing
We'd like to perform hypothesis tests on the following variables: Temperature, Humidity, Industrial Levels, and Day of Week.

We'll start by examining whether Temperature has an effect on the concentration of Particulate Matter. We'll use the following set of hypothesis:


\[
\begin{aligned}
&H_0: \beta_{temp} = \beta_{hum:temp} = 0 \\
&H_A: \beta_{temp} \neq 0 \text{ and } \beta_{hum:temp} \neq 0
\end{aligned}\]

\
We'll compare the restricted model with the unrestricted model:

```{r, eval=FALSE}
model_unrestricted <- lm(particulate_matter ~ . + 
                         temperature:humidity,
                         data=data_tidy_air_quality)
model_restricted <- update(model_unrestricted, .~.
                           - temperature
                           - temperature:humidity)
anova(model_restricted, model_restricted)
 
```
Using the anova function in R, we compare the two models with F test. The F test yields a P value 0.6815, suggesting that temperature doesn't have a significant effect on the concentration of particular matter.

We now test for the effect of humidity. Repeating the same procedure, we obtain a P value < 0.00001. Suggesting that it's likely that humidity has an effect on the concentration of particulate matters.
\[
\begin{aligned}
&H_0: \beta_{hum} = \beta_{hum:temp} = 0 \\
&H_A: \beta_{hum} \neq 0 \text{ and } \beta_{hum:temp} \neq 0
\end{aligned}
\]



```{r, eval=FALSE}
model_unrestricted <- lm(particulate_matter ~ . + 
                         temperature:humidity,
                         data=data_tidy_air_quality)
model_restricted <- update(model_unrestricted, .~.
                           - humidity
                           - temperature:humidity)
anova(model_restricted, model_unrestricted)
```


### Categorical Variables
For the day of week, we take Monday as the reference category and test for the following set of hypothesis, using the same procedure.
\[
\begin{aligned}
&H_0: \beta_{Tuesday} = \beta_{Wednesday} = \beta_{Thursday} = \beta_{Friday} = \beta_{Saturday} = \beta_{Sunday} = 0 \\
&H_A: \beta_{Tuesday} \neq 0 \text{ and } \beta_{Wednesday} \neq 0 \text{ and } \beta_{Thursday} \neq 0 \text{ and } \beta_{Friday} \neq 0 \text{ and } \beta_{Saturday} \neq 0 \text{ and } \beta_{Sunday} \neq 0
\end{aligned}
\]
```{r, eval=FALSE}
data_tidy_air_quality$day_of_week <- 
  relevel(factor(data_tidy_air_quality$day_of_week), ref="Monday")
model_unrestricted <- lm(particulate_matter ~ .,
                         data=data_tidy_air_quality)
model_restricted <- update(model_unrestricted, .~.
                           - day_of_week)
anova(model_restricted, model_unrestricted)
```
The P value is 0.7735, indicating that we cannot reject the null hypothesis at 5% significance level.

We do the same for industrial activity, taking No Activity as the reference category to test for the set of hypothesis:
\[
\begin{aligned}
&H_0: \beta_{Low} = \beta_{Moderate} = \beta_{High} = 0 \\
&H_A: \beta_{Low} \neq 0 \text{ and } \beta_{Moderate} \neq 0 \text{ and } \beta_{High} \neq 0 
\end{aligned}
\]
```{r, eval=FALSE}
data_tidy_air_quality$industrial_activity <-
  relevel(factor(data_tidy_air_quality$industrial_activity), ref="None")
model_unrestricted <- lm(particulate_matter ~ .,
                         data_tidy_air_quality)
model_restricted <- lm(particulate_matter ~ . - industrial_activity,
                       data_tidy_air_quality)
anova(model_restricted, model_unrestricted)
```
We obtain a P-value of 0.0707, suggesting that we cannot reject the null hypothesis at 5% significance level.

## Intepretation
From the hypothesis tests above, we concluded that Humidity (p-value: < 0.0001) has a significant effect (p-value less than or equal to 0.05) on the concentration of particulate matter. However, from the summary output, which conducts t-tests on the individual coefficients of the model, we found that Moderate Industrial Activity (p-value: 0.03), Traffic Density (p-value: 0.0155), and Urban Greenery (p-value: < 0.0001) also have significant effects on the concentration of particulate matter. Furthermore, looking at the confidence interval table, it seems that High Industrial Activity also has an effect on concentration levels, despite having a p-value of 0.06, which indicates no significant effect at the 5% significance level.

The average increase in concentration of particulate matter due to Moderate Industrial Activity is estimated to be 6.4545 $\mu g/m^3$ (95% CI: 0.6047, 12.3043), while holding all other variables constant. This indicates a positive association between moderate industrial activity and particulate matter concentration, although the precise effect is unclear, as the confidence interval is quite wide. A similar interpretation applies to High Industrial Activity, which causes an estimated average increase in particulate matter concentration of 5.3652 $\mu g/m^3$ (95% CI: -0.2503, 10.9806). Although this confidence interval includes zero, the fact that most of the interval is positive hints at a potential positive correlation.

The average increase in particulate matter concentration caused by Traffic Densityâ€”that is, one additional vehicle per hour, while holding all other explanatory variables constantâ€”is estimated to be 0.0799 $\mu g/m^3$ (95% CI: 0.0155, 0.1444), indicating a positive correlation.

The average decrease in particulate matter concentration due to a one-unit increase in the percentage of Urban Greenery is estimated to be 0.2954 $\mu g/m^3$ (95% CI: -0.4142, -0.1766), indicating a strong negative association between urban greenery and particulate matter concentration.

The effect of humidity interacts with temperature in the model, but we can only examine these effects separately. Holding other variables constant, the estimated increase in particulate matter concentration caused by a one-unit increase in humidity is 0.2 $\mu g/m^3$ (95% CI: -0.1111, 0.4962), suggesting that, on average, increased humidity leads to higher particulate matter concentration. However, because the confidence interval includes negative values, this inference is less robust, and might just be a result of random chance. The interaction between humidity and temperature has a similar effect: an estimated increase of 0.0061 $\mu g/m^3$ (95% CI: -0.0088, 0.201). Again, the confidence interval includes negative values, making the result less significant.

Despite these findings, the F-test on humidity suggests a different conclusion. The p-value for humidity is extremely small (< 0.0001), indicating that, overall, humidity does have an effect on particulate matter concentration. However, we cannot precisely determine the magnitude of this effect based solely on the individual confidence intervals.

# Conclusion
In this part of the report, we explored the effects of various factors on the concentration of particulate matter. Our analysis found that humidity, moderate-level industrial activity, high-level industrial activity, and traffic density tend to increase the concentration of particulate matter. In contrast, the percentage of area covered by urban greenery was found to decrease particulate matter concentration.

It is well-known that high concentrations of particulate matter can lead to serious health issues. Based on these findings, we recommend that city planners to carefully consider the levels of industrial activity and traffic density permitted in urban areas. A balanced approach is necessary to weigh the economic benefits of industrial development against the health of citizens. To control particulate matter concentrations, one effective strategy is to increase the percentage of urban areas covered by greenery.

Further research on balancing economic development and public health is essential, as well as other effective strategies to mitigate high particulate matters level. While industrial development is necessary for economic growth, ensuring the health and well-being of the population is equally critical.

# part 2

For reference, we first calculate the type I rate without breaking any of the model assumptions. We know a prior that the response variable is not correlated with temperature, as we have artificially constructed the response variable to be $30 + e$, where e is just some random noises. Therefore, we expect the type I error rate to be very closed to 0.05.



## Scenario A:
### Methodology
We know that there is no correlation between temperature and the response variable as the variation in it is caused by random noises. So any rejection of the null hypothesis is a type I error.

Simulation under the null hypothesis ($\beta_{1}$= 0):

We simulate the data assuming $\beta_{0}$ = 30, $\beta_{1}$= 0, and errors are uniformly distributed.
The errors will be sampled from a uniform distribution where $e \sim U(a,b)$ with the constraint that $Var(e)$ = 100

For a uniform distribution $e \sim U(a,b)$ with a variance $\sigma^2$ = 100, $Var(e) = \frac{(b-a)^2}{12}$. Solving for $a$ and $b$ we get $a = -17.32$ and $b= 17.32$

To simulate our data, we created a function 'run_simulation' which runs a simulation once. In a simulation, we used _runif(length(temperature), min = a, max = b)_   to generate random errors. Next calculated $Y_{i}=30 + e$ as the vector of response variables for the trial. We then used the lm function to fit our regression model. We extracted p values from our model, and ran _ifelse_ statement to check whether our null hypothesis was rejected or not, at 5% significance level. Then we used the _replicate()_ function to run the simulation 1000 times. Finally, we counted the number of null hypothesis rejected and we observed that our type 1 error rate for this scenario is 0.044 

### Results
Type I error is the probability of incorrectly rejecting the null hypothesis when it is true (false positive). Under the null hypothesis, the expected Type I error rate should be equal to the chosen significance level, typically 0.05. 

We have found that the Type I error rate is 0.044, which is less than the expected 0.05. This can be partly explained by that uniform distributions are bounded, meaning that values drawn from it are more tightly spread compared to values drawn from a normal distribution, which can take on more extreme values due to its unbounded nature. This results in the simulated error term, and thus the response variable, having less variation. This leads to $\beta_1$ being less likely to deviate from zero, as stated by the null hypothesis. However, linear models are known to be fairly stable

For interest's sake, if we increase the number of simulations to 10000, the Type I error rate becomes 0.0501, which is much closer to the expected 0.05. However, if we fix the number of simulations to 1000 and reduce each sample size to only 3 observations, the Type I error rate drops to 0.036, which is much smaller than the expected 0.05.

This can be explained by the fact that despite the model violation (using uniformly distributed errors instead of normally distributed ones), the Central Limit Theorem helps mitigate the impact as the sample size increases. With 150 observations per sample and 10000 samples in total, the distribution of the sample means of the estimated coefficients approaches normality, making the Type I error rate approach the expected value.. With smaller sample sizes, the uniform errors result in less variation in the estimates, leading to a lower Type I error rate.


```{r include=FALSE}
library(tidyverse)
# Set the seed for reproducibility
set.seed(123)

# Number of simulations
n_simulations <- 1000

temperature <- data_tidy_air_quality$temperature

# Variance of the uniform distribution needs to be 100, so we calculated b = 17.32
a <- -17.32
b <- 17.32

# Function to run a single simulation
run_simulation <- function() {
  
  # Generate error term e ~ Uniform(a, b)
  e_unif <- runif(length(temperature), min = a, max = b)
  e_unif_small<-runif(3, a, b)
  e_norm <- rnorm(3, 0, 10)
  
  # Generate Y = 30 + e (since b1 = 0)
  Y <- 30 + e_unif
  
  # Fit the linear model Y = b0 + b1 * temperature
  model <- lm(Y ~ temperature)
  #model_small <- lm(Y ~ temperature[1:3])
  
  # Perform hypothesis test on b1 (null hypothesis: b1 = 0) and extract p-value
  p_value <- summary(model)$coefficients[2, 4]
  
  # Return whether the null hypothesis is rejected (a = 0.05)
  return(ifelse(p_value < 0.05, 1, 0))
}


# Run all simulations using repliscate 
reject_null <- replicate(n_simulations, run_simulation())

# Calculate Type I error rate (proportion of times the null was incorrectly rejected)

type_1_error_rate <- mean(reject_null)

# Output the Type I error rate
type_1_error_rate
```


## Scenario B:

### Methodology

Again we created a single function to run a single simulation. In each simulation, We simulate the error variances using the normal distribution with mean of 100 and variance of 50.Then we simulated error terms using a normal distribution with a mean of 0 and a variance of our error_variance calculated before. This ensures that our errors have a non constant variance. We then repeated the same steps as above to obtain our type 1 error rate. Our observed type 1 error rate is 0.046.


### Results
The observed type 1 error rate is 0.046, less than the expected 0.05. This is caused by the heteroscedasticity we intentionally introduced to the model. Constant variance is one of the key assumptions for the Gauss-Markov theorem. By breaking the assumption, the ordinary least square estimate(OLS) for $\beta_1$, $\hat{\beta_1}$ is no longer guaranteed to be the bestlinear unbiased estimate(BLUE), thereby making the type I error rate inaccurate. As a side note, based on empirical results, increasing the variability of error's variances actually make the type I error rate closer to 0.05. The reason is way beyond our knowledge but might have something to do with Berry-Esseen Theorem based on our failed attempt at searching for an answer :(.
```{r include=FALSE}
# For reproducibility

# Number of observations in temperature data
temperature <- temperature[1:5]
n <- length(temperature)
# Number of simulations
n_simulations <- 1000
set.seed(123)
# Function to run a single simulation
run_simulation <- function() {

  # Simulate heteroscedastic errors with mean variance 100 and variance of the variances = 50
  error_variances <- abs(rnorm(n, 100, sqrt(50) )) # Variance of each error term
  #error_variances_gamma <- rgamma(n, 200, rate = 2)
  e <- rnorm(n, mean = 0, sqrt(error_variances))  # Simulated errors with heteroscedasticity
  #e_constant <- rnorm(n, mean = 0, 100)
  # Generate Y values under null hypothesis (beta_1 = 0)
  Y <- 30 + e
  
  # Fit the model Y ~ temperature
  model <- lm(Y ~ temperature)
  
  # Perform hypothesis test for beta_1 (test if beta_1 = 0)
  p_value <- summary(model)$coefficients[2, 4]  # Extract p-value for temperature coefficient
  
  # Return whether the null hypothesis is rejected (p-value < 0.05)
  return(as.numeric(p_value < 0.05))
}

# Run all simulations using replicate
reject_null <- replicate(n_simulations, run_simulation())

# Calculate the Type I error rate (proportion of rejected null hypotheses)
type_1_error_rate <- mean(reject_null)

# Print the Type I error rate
type_1_error_rate

```


## Scenario C:

### Methodology and discussion of results for Scenario C:
Using our function again, we replicate 1000 simulations,but this time we test the dependence of errors in our model. To generate Correlated errors in our model we, use the provided function given to us. As above we repeated the same steps in order to obtain the proportion of the number of times our null hypothesis  was incorrectly rejected. Our type 1 errot rate was 0.053.

Autocorrelation violates the assumption of independent errors in linear regression. Again, independence of the error terms is another key assumption of the Gauss-Markov Theorem. Breaking the assumptions lead to the ordinary least square (OLS) estimator for $\beta_1$, $\hat{\beta_1}$, not necessarily being the best linear unbiased estimator (BLUE), making the inferences on $\beta_1$ inaccurate.

Typically, autocorrelated errors inflate Type I errors if unaccounted for because the model underestimates the true error variability. However, depending on the specific pattern of autocorrelation and sample size, this effect can vary.
```{r include=FALSE}
# Set the seed for reproducibility
set.seed(123)

# Get the temperature data
temperature <- data_tidy_air_quality$temperature

n <- length(temperature)  # Number of observations in temperature data
n_sim <- 1000  # Number of simulations

rho <- 0.3  # Autocorrelation coefficient
var_epsilon <- 100  # Desired variance of errors

# Function to generate autocorrelated errors
generate_ar1_errors <- function(n, rho, var_epsilon) {
  sigma_u_squared <- var_epsilon * (1 - rho^2)
  u <- rnorm(n, mean = 0, sd = sqrt(sigma_u_squared))
  epsilon <- numeric(n)
  epsilon[1] <- u[1]
  for (i in 2:n) {
    epsilon[i] <- rho * epsilon[i - 1] + u[i]
  }
  return(epsilon)
}

# Function to run a single simulation
run_simulation <- function(n, rho, var_epsilon) {
  # Generate autocorrelated errors
  e <- generate_ar1_errors(n, rho, var_epsilon)
  
  # Generate Y values under null hypothesis (beta_1 = 0)
  Y <- 30 + e
  
  # Fit the model Y ~ temperature
  model <- lm(Y ~ temperature)
  
  # Perform hypothesis test for beta_1 (test if beta_1 = 0)
  p_value <- summary(model)$coefficients[2, 4]  # Extract p-value for temperature coefficient
  
  # Return whether the null hypothesis is rejected (p-value < 0.05)
  return(as.numeric(p_value < 0.05))
}

# Run all simulations using replicate
reject_null <- replicate(n_sim, run_simulation(n, rho, var_epsilon))

# Calculate the Type I error rate (proportion of rejected null hypotheses)
type_1_error_rate <- mean(reject_null)

# Print the Type I error rate
type_1_error_rate
```

## Conclusion